{
  "comments": [
    {
      "key": {
        "uuid": "07ec9c13_0d8684ed",
        "filename": "org.eclipse.jgit/src/org/eclipse/jgit/internal/storage/commitgraph/CommitGraphDataV1.java",
        "patchSetId": 9
      },
      "lineNbr": 203,
      "author": {
        "id": 5082
      },
      "writtenOn": "2021-10-15T16:13:06Z",
      "side": 1,
      "message": "If I am understanding the code in the class correctly, the constructor loads the entire file in memory upfront? It also looks like this is using a binary search to find objectId positions? I think the file format was designed to make binary searching possible without loading the entire file in memory, and I would expect a binary search to be used with that approach. Since this class seems to be using a load-the-entire-file approach, a binary search is likely not the most efficient approach O(log(n)), using a ObjectIdMap probably makes more sense O(1)?",
      "revId": "ee378663ef427303b8f09a34202897fef8e2eaf4",
      "serverId": "97ee7c02-f12f-4043-b43e-dea463d88b31",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "0d404f5b_cbd4c440",
        "filename": "org.eclipse.jgit/src/org/eclipse/jgit/internal/storage/commitgraph/CommitGraphDataV1.java",
        "patchSetId": 9
      },
      "lineNbr": 203,
      "author": {
        "id": 304466
      },
      "writtenOn": "2021-10-18T02:40:17Z",
      "side": 1,
      "message": "\u003e If I am understanding the code in the class correctly, the constructor loads the entire file in memory upfront? \nYes\n\u003e It also looks like this is using a binary search to find objectId positions? \nYes\n\n\u003e I think the file format was designed to make binary searching possible without loading the entire file in memory, and I would expect a binary search to be used with that approach. \nNo, It still requires all files to be mapped into memory. If you have looked at CGit code, you would see that CGit maps the entire file into memory using mmap[1].\n   graph_map \u003d xmmap(NULL, graph_size, PROT_READ, MAP_PRIVATE, fd, 0);\n\nThis is very similar to PackIndex, which is an index for binary lookup and fully loaded in memory in JGit.\n\n[1] https://github.com/git/git/commit/2a2e32bdc5a80221981939e77643cec3462b4793",
      "parentUuid": "07ec9c13_0d8684ed",
      "revId": "ee378663ef427303b8f09a34202897fef8e2eaf4",
      "serverId": "97ee7c02-f12f-4043-b43e-dea463d88b31",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "4820bc42_357eace0",
        "filename": "org.eclipse.jgit/src/org/eclipse/jgit/internal/storage/commitgraph/CommitGraphDataV1.java",
        "patchSetId": 9
      },
      "lineNbr": 203,
      "author": {
        "id": 5082
      },
      "writtenOn": "2021-10-19T22:17:12Z",
      "side": 1,
      "message": "\u003e \u003e I think the file format was designed to make binary searching possible without loading the entire file in memory, and I would expect a binary search to be used with that approach. \n\u003e No, It still requires all files to be mapped into memory. If you have looked at CGit code, you would see that CGit maps the entire file into memory using mmap[1].\n\u003e    graph_map \u003d xmmap(NULL, graph_size, PROT_READ, MAP_PRIVATE, fd, 0);\n\nmmap() is a lazy IO operation, i.e. it will only load those portions of a file which are actually accessed. From what I can tell here: https://github.com/git/git/blob/2a2e32bdc5a80221981939e77643cec3462b4793/commit-graph.c it looks like CGit mmap()s the file to a pointer on line 81, and after that if things go well, it places that pointer along with a \"still open\" filedescriptor into the \u0027graph\u0027 struct, and then it returns that \u0027graph\u0027 struct on line 174 without closing the file. If the entire file were already read, would they not have closed the file? \n\nI believe the commit graph (and the .idx file) was designed to be fast for programs which startup, read a few commits, and then exit. This is the typical C Git command line usage. Such programs don\u0027t have the benefit of being able to cache an index across many user invocations. This mmap/binary search operation allows a program to avoid reading the whole file which is very expensive for the normal C Git use cases.\n\nHowever most JGit applications, such as eclipse and Gerrit, can benefit from caching the contents of indexes across many different unrelated user operations. So it certainly would be valuable to have the ability to read the entire commit graph into memory, but that may be expensive in some situations (when only a few commits need to be looked up). We may also eventually want the ability to do an mmap() binary search. However, I am not suggesting that you have to implement both ways to introduce commit graphs to JGit, just that depending on which approach is picked, that we then use the right lookup approach to go with it.\n\n\u003e This is very similar to PackIndex, which is an index for binary lookup and fully loaded in memory in JGit.\n\nIf we are going to load the entire commit graph in memory, and then do a binary search, then I think we need to justify why, either because it is faster or because it saves memory. I would not assume that just because PackIndex does things that way (and it does appear to), that it is a good way to do things.\n\nI don\u0027t know why PackInded does this, and it probably could be improved to not do that. Although improving PackIndex to have an O(1) lookup may not make much of a difference in practice because usually the index is only used to then do I/O to fetch an object from the pack anyway. However, it might help in the case of not found objects (Bup suffered here), especially/and when there are many packs (which is terribly slow now in jgit). Perhaps the PackIndex code was originally written to do an mmap() and then it turned out not to work well in java, but then the binary lookup code was just left behind? It sure would be nice to be able to improve something this fundamental for JGit!\n\nAs for Commit Graphs, the use case that they are intended to improved, is one of accessing many commits without doing I/O. In this case, the extra cost of an O(log(n)) lookup could be significant compared to an O(1) lookup?",
      "parentUuid": "0d404f5b_cbd4c440",
      "revId": "ee378663ef427303b8f09a34202897fef8e2eaf4",
      "serverId": "97ee7c02-f12f-4043-b43e-dea463d88b31",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "30f4778f_d6e7c47e",
        "filename": "org.eclipse.jgit/src/org/eclipse/jgit/internal/storage/commitgraph/CommitGraphDataV1.java",
        "patchSetId": 9
      },
      "lineNbr": 203,
      "author": {
        "id": 304466
      },
      "writtenOn": "2021-10-20T04:27:47Z",
      "side": 1,
      "message": "Thank you for all your comments.\n\n\n\u003e mmap() is a lazy IO operation, i.e. it will only load those portions of a file which are actually accessed. From what I can tell here: https://github.com/git/git/blob/2a2e32bdc5a80221981939e77643cec3462b4793/commit-graph.c it looks like CGit mmap()s the file to a pointer on line 81, and after that if things go well, it places that pointer along with a \"still open\" filedescriptor into the \u0027graph\u0027 struct, and then it returns that \u0027graph\u0027 struct on line 174 without closing the file. If the entire file were already read, would they not have closed the file? \n\nYes, it\u0027s true that mmap doesn\u0027t read all into memory. \nC language\u0027s mmap() has a low performance cost and is easy to use, which makes me feel like I\u0027m reading the entire file and storing it in memory.\n\n\u003e I believe the commit graph (and the .idx file) was designed to be fast for programs which startup, read a few commits, and then exit. This is the typical C Git command line usage. Such programs don\u0027t have the benefit of being able to cache an index across many user invocations. This mmap/binary search operation allows a program to avoid reading the whole file which is very expensive for the normal C Git use cases.\n\n\u003e However most JGit applications, such as eclipse and Gerrit, can benefit from caching the contents of indexes across many different unrelated user operations. So it certainly would be valuable to have the ability to read the entire commit graph into memory, but that may be expensive in some situations (when only a few commits need to be looked up). We may also eventually want the ability to do an mmap() binary search. However, I am not suggesting that you have to implement both ways to introduce commit graphs to JGit, just that depending on which approach is picked, that we then use the right lookup approach to go with it.\n\n\u003e If we are going to load the entire commit graph in memory, and then do a binary search, then I think we need to justify why, either because it is faster or because it saves memory. I would not assume that just because PackIndex does things that way (and it does appear to), that it is a good way to do things.\n\nI thought about teaching JGit to have the ability to do an mmap() binary search before，but didn\u0027t implement it. There are several reasons:\n 1. Unlike CGit, JGit has a DFSRepository type. As you can see, Jgit use InputStream to read \nfiles in many places，such as PackIndex、PackBitmapIndex. Since DFSRepository does not fetch \ndata directly from the file system, mmap() is not available. \n\n 2. If we support mmap() only for FileRepository, this means we need to refactor a lot of code because many classes are shared between DFSRepository and FileRepository. This means that we should spend a lot of time doing it, but the benefits don\u0027t seem obvious.\n\n 3. We uses RepositoryCache.open() to get Repository, and in this case, commit-graph will most likely only need to be initialized once without causing a significant performance loss. \n\n 4. Java language\u0027s mmap library is not as useful as the C language. Before I tried to use mmap() to read the Pack (use WindowCacheConfig.SetPackedGitMMAP), but there doesn\u0027t seem to be better, but slower. So I\u0027m not sure if implementing this for commit-Graph would be better.\n\n\n\u003e However, it might help in the case of not found objects (Bup suffered here), especially/and when there are many packs (which is terribly slow now in jgit).\n\nThe multi-pack-index[1] can help solve this problem, maybe we can work on that in the future.\n\n\u003e As for Commit Graphs, the use case that they are intended to improved, is one of accessing many commits without doing I/O. In this case, the extra cost of an O(log(n)) lookup could be significant compared to an O(1) lookup?\n\n\nOID Fanout Chunk and OID Lookup Chunk are designed to provide binary lookup, see [2].\nThese actually serves the same function as .idx file. \nCommit-graph currently focuses on these two main costs instead of the complexity of the lookup:\n\n 1. Decompressing and parsing commits.\n\n 2. Walking the entire graph to satisfy topological order constraints.\n\nfor more detail:[3].\n\nO(1) lookup looks pretty good! If this is implemented, not only commit-graph, but.idx will see significant performance improvements.\nThis means that we need to design an on-disk format to meet this requirement. This will be a long-term study, but it may not be urgent :) .\n\nRegards, Kyle.\n\n\n[1] https://bugs.eclipse.org/bugs/show_bug.cgi?id\u003d573675\n\n[2] https://git-scm.com/docs/commit-graph-format/2.21.0\n\n[3] https://git-scm.com/docs/commit-graph",
      "parentUuid": "4820bc42_357eace0",
      "revId": "ee378663ef427303b8f09a34202897fef8e2eaf4",
      "serverId": "97ee7c02-f12f-4043-b43e-dea463d88b31",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "8685ebff_9e1307b6",
        "filename": "org.eclipse.jgit/src/org/eclipse/jgit/internal/storage/commitgraph/CommitGraphDataV1.java",
        "patchSetId": 9
      },
      "lineNbr": 203,
      "author": {
        "id": 5082
      },
      "writtenOn": "2021-10-20T04:50:14Z",
      "side": 1,
      "message": "\u003e I thought about teaching JGit to have the ability to do an mmap() binary search before，but didn\u0027t implement it. There are several reasons:\n...\nYou make many great points about mmap that I agree with! My point is not so much that we should be mmaping, but rather that the on disk format was designed for this..\n\n\u003e \u003e However, it might help in the case of not found objects (Bup suffered here), especially/and when there are many packs (which is terribly slow now in jgit).\n\u003e \n\u003e The multi-pack-index[1] can help solve this problem, maybe we can work on that in the future.\n\nIndeed, that would be great!\n\n\u003e \u003e As for Commit Graphs, the use case that they are intended to improved, is one of accessing many commits without doing I/O. In this case, the extra cost of an O(log(n)) lookup could be significant compared to an O(1) lookup?\n\u003e \n\u003e OID Fanout Chunk and OID Lookup Chunk are designed to provide binary lookup, see [2].\n\u003e These actually serves the same function as .idx file. \n\u003e Commit-graph currently focuses on these two main costs instead of the complexity of the lookup:\n\u003e \n\u003e  1. Decompressing and parsing commits.\n\u003e \n\u003e  2. Walking the entire graph to satisfy topological order constraints.\n\u003e \n\u003e for more detail:[3].\n\nYes, agreed.\n\n\u003e\u003e O(1) lookup looks pretty good! If this is implemented, not only commit-graph, but.idx will see significant performance improvements.\n\u003e This means that we need to design an on-disk format to meet this requirement. \n\nI disagree with this conclusion. Just because the format on disk is designed for binary search, does not mean that once we have the data in memory that we are limited to a binary search. Did you understand my suggestion of using loading a HashMap (better a ObjectIdMaP) with the objectIds on file load?",
      "parentUuid": "30f4778f_d6e7c47e",
      "revId": "ee378663ef427303b8f09a34202897fef8e2eaf4",
      "serverId": "97ee7c02-f12f-4043-b43e-dea463d88b31",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "be79d65a_bcc47918",
        "filename": "org.eclipse.jgit/src/org/eclipse/jgit/internal/storage/commitgraph/CommitGraphDataV1.java",
        "patchSetId": 9
      },
      "lineNbr": 203,
      "author": {
        "id": 304466
      },
      "writtenOn": "2021-10-20T05:32:27Z",
      "side": 1,
      "message": "\u003e I disagree with this conclusion. Just because the format on disk is designed for binary search, does not mean that once we have the data in memory that we are limited to a binary search. Did you understand my suggestion of using loading a HashMap (better a ObjectIdMaP) with the objectIds on file load?\n\nDoes this mean that when the commit-graph is initialized, we need to iterate over all the commit using binary lookups?\nIf there are a lot of commits, initialization can take much time.",
      "parentUuid": "8685ebff_9e1307b6",
      "revId": "ee378663ef427303b8f09a34202897fef8e2eaf4",
      "serverId": "97ee7c02-f12f-4043-b43e-dea463d88b31",
      "unresolved": true
    },
    {
      "key": {
        "uuid": "81af9827_710835da",
        "filename": "org.eclipse.jgit/src/org/eclipse/jgit/internal/storage/commitgraph/CommitGraphDataV1.java",
        "patchSetId": 9
      },
      "lineNbr": 203,
      "author": {
        "id": 304466
      },
      "writtenOn": "2021-10-20T11:11:05Z",
      "side": 1,
      "message": "\u003e \u003e I disagree with this conclusion. Just because the format on disk is designed for binary search, does not mean that once we have the data in memory that we are limited to a binary search. Did you understand my suggestion of using loading a HashMap (better a ObjectIdMaP) with the objectIds on file load?\n\u003e \n\u003e Does this mean that when the commit-graph is initialized, we need to iterate over all the commit using binary lookups?\n\ncorrect:  don\u0027t need to use binary lookups, the comment above is a bit wrong\n\n\u003e If there are a lot of commits, initialization can take much time.\n\nIf we were to use hashMap for storage, we would need to iterate through all the commits of OID Lookup Chunk、convert them to objectId、and put it to the map.\n\nThis makes loading even more complicated, because there is a lot more computation going on in addition to I/O, and the time of computation depends on the number of commits.The loading time would be easily over 100ms.\n\nI\u0027m not sure that\u0027s worth it.",
      "parentUuid": "be79d65a_bcc47918",
      "revId": "ee378663ef427303b8f09a34202897fef8e2eaf4",
      "serverId": "97ee7c02-f12f-4043-b43e-dea463d88b31",
      "unresolved": true
    }
  ]
}